{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For time series forecasting we're leveraging AutoGluon Framework since it provides support for a \n",
    "large number of probabilistic algorithms including deep learning and transformer based algorithms.\n",
    "\n",
    "This notebook contains the code for the following steps:\n",
    "1. Model selection\n",
    "2. Hyperparameter tuning \n",
    "\n",
    "The model selected in this step is used for Model training and deployment in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/Homepro_AWS_competancy/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data saved from Feature creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read timeseries and static features data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>target</th>\n",
       "      <th>net_revenue_sum</th>\n",
       "      <th>listing_price_mean</th>\n",
       "      <th>net_unit_price</th>\n",
       "      <th>promo_flag</th>\n",
       "      <th>holiday_flag</th>\n",
       "      <th>weekend_flag</th>\n",
       "      <th>holiday_ahead</th>\n",
       "      <th>promo_ahead</th>\n",
       "      <th>item_height</th>\n",
       "      <th>item_width</th>\n",
       "      <th>item_length</th>\n",
       "      <th>item_weight</th>\n",
       "      <th>article_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ITEM0001</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>640.0</td>\n",
       "      <td>35200.00</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>29.53</td>\n",
       "      <td>82.49</td>\n",
       "      <td>89.19</td>\n",
       "      <td>4.01</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ITEM0001</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>838.0</td>\n",
       "      <td>46090.00</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>29.53</td>\n",
       "      <td>82.49</td>\n",
       "      <td>89.19</td>\n",
       "      <td>4.01</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ITEM0001</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>956.0</td>\n",
       "      <td>52580.00</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>29.53</td>\n",
       "      <td>82.49</td>\n",
       "      <td>89.19</td>\n",
       "      <td>4.01</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ITEM0001</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>80685.00</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>29.53</td>\n",
       "      <td>82.49</td>\n",
       "      <td>89.19</td>\n",
       "      <td>4.01</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ITEM0001</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1372.0</td>\n",
       "      <td>75456.47</td>\n",
       "      <td>55.007605</td>\n",
       "      <td>54.997427</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>29.53</td>\n",
       "      <td>82.49</td>\n",
       "      <td>89.19</td>\n",
       "      <td>4.01</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122842</th>\n",
       "      <td>ITEM0100</td>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>42.0</td>\n",
       "      <td>56700.00</td>\n",
       "      <td>1350.000000</td>\n",
       "      <td>1350.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>92.30</td>\n",
       "      <td>16.26</td>\n",
       "      <td>81.72</td>\n",
       "      <td>17.57</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122843</th>\n",
       "      <td>ITEM0100</td>\n",
       "      <td>2024-01-28</td>\n",
       "      <td>55.0</td>\n",
       "      <td>74250.00</td>\n",
       "      <td>1350.000000</td>\n",
       "      <td>1350.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>92.30</td>\n",
       "      <td>16.26</td>\n",
       "      <td>81.72</td>\n",
       "      <td>17.57</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122844</th>\n",
       "      <td>ITEM0100</td>\n",
       "      <td>2024-01-29</td>\n",
       "      <td>46.0</td>\n",
       "      <td>62100.00</td>\n",
       "      <td>1350.000000</td>\n",
       "      <td>1350.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>92.30</td>\n",
       "      <td>16.26</td>\n",
       "      <td>81.72</td>\n",
       "      <td>17.57</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122845</th>\n",
       "      <td>ITEM0100</td>\n",
       "      <td>2024-01-30</td>\n",
       "      <td>32.0</td>\n",
       "      <td>43200.00</td>\n",
       "      <td>1350.000000</td>\n",
       "      <td>1350.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>92.30</td>\n",
       "      <td>16.26</td>\n",
       "      <td>81.72</td>\n",
       "      <td>17.57</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122846</th>\n",
       "      <td>ITEM0100</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>26.0</td>\n",
       "      <td>35100.00</td>\n",
       "      <td>1350.000000</td>\n",
       "      <td>1350.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>92.30</td>\n",
       "      <td>16.26</td>\n",
       "      <td>81.72</td>\n",
       "      <td>17.57</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122847 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id   timestamp  target  net_revenue_sum  listing_price_mean  \\\n",
       "0       ITEM0001  2020-01-01   640.0         35200.00           55.000000   \n",
       "1       ITEM0001  2020-01-02   838.0         46090.00           55.000000   \n",
       "2       ITEM0001  2020-01-03   956.0         52580.00           55.000000   \n",
       "3       ITEM0001  2020-01-04  1467.0         80685.00           55.000000   \n",
       "4       ITEM0001  2020-01-05  1372.0         75456.47           55.007605   \n",
       "...          ...         ...     ...              ...                 ...   \n",
       "122842  ITEM0100  2024-01-27    42.0         56700.00         1350.000000   \n",
       "122843  ITEM0100  2024-01-28    55.0         74250.00         1350.000000   \n",
       "122844  ITEM0100  2024-01-29    46.0         62100.00         1350.000000   \n",
       "122845  ITEM0100  2024-01-30    32.0         43200.00         1350.000000   \n",
       "122846  ITEM0100  2024-01-31    26.0         35100.00         1350.000000   \n",
       "\n",
       "        net_unit_price  promo_flag  holiday_flag  weekend_flag  holiday_ahead  \\\n",
       "0            55.000000        True          True         False          False   \n",
       "1            55.000000        True         False         False          False   \n",
       "2            55.000000        True         False         False          False   \n",
       "3            55.000000        True         False          True          False   \n",
       "4            54.997427        True         False          True          False   \n",
       "...                ...         ...           ...           ...            ...   \n",
       "122842     1350.000000        True         False          True          False   \n",
       "122843     1350.000000       False         False          True          False   \n",
       "122844     1350.000000       False         False         False          False   \n",
       "122845     1350.000000       False         False         False          False   \n",
       "122846     1350.000000       False         False         False          False   \n",
       "\n",
       "        promo_ahead  item_height  item_width  item_length  item_weight  \\\n",
       "0              True        29.53       82.49        89.19         4.01   \n",
       "1              True        29.53       82.49        89.19         4.01   \n",
       "2              True        29.53       82.49        89.19         4.01   \n",
       "3              True        29.53       82.49        89.19         4.01   \n",
       "4              True        29.53       82.49        89.19         4.01   \n",
       "...             ...          ...         ...          ...          ...   \n",
       "122842        False        92.30       16.26        81.72        17.57   \n",
       "122843        False        92.30       16.26        81.72        17.57   \n",
       "122844        False        92.30       16.26        81.72        17.57   \n",
       "122845        False        92.30       16.26        81.72        17.57   \n",
       "122846        False        92.30       16.26        81.72        17.57   \n",
       "\n",
       "       article_category  \n",
       "0           Electronics  \n",
       "1           Electronics  \n",
       "2           Electronics  \n",
       "3           Electronics  \n",
       "4           Electronics  \n",
       "...                 ...  \n",
       "122842      Electronics  \n",
       "122843      Electronics  \n",
       "122844      Electronics  \n",
       "122845      Electronics  \n",
       "122846      Electronics  \n",
       "\n",
       "[122847 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read the file \n",
    "df_ts = pd.read_csv('../data/final_aggregated_data.csv')\n",
    "df_ts.rename(columns={'transaction_date':'timestamp','sales_quantity_sum':'target'},inplace = True)\n",
    "df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_height</th>\n",
       "      <th>item_width</th>\n",
       "      <th>item_length</th>\n",
       "      <th>item_weight</th>\n",
       "      <th>article_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ITEM0001</td>\n",
       "      <td>29.53</td>\n",
       "      <td>82.49</td>\n",
       "      <td>89.19</td>\n",
       "      <td>4.01</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ITEM0002</td>\n",
       "      <td>69.36</td>\n",
       "      <td>2.95</td>\n",
       "      <td>19.64</td>\n",
       "      <td>18.04</td>\n",
       "      <td>Toys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ITEM0003</td>\n",
       "      <td>86.38</td>\n",
       "      <td>59.71</td>\n",
       "      <td>34.78</td>\n",
       "      <td>6.12</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ITEM0004</td>\n",
       "      <td>83.84</td>\n",
       "      <td>78.03</td>\n",
       "      <td>89.58</td>\n",
       "      <td>15.34</td>\n",
       "      <td>Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ITEM0005</td>\n",
       "      <td>16.68</td>\n",
       "      <td>44.55</td>\n",
       "      <td>64.05</td>\n",
       "      <td>17.96</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>ITEM0496</td>\n",
       "      <td>50.30</td>\n",
       "      <td>63.68</td>\n",
       "      <td>84.41</td>\n",
       "      <td>8.84</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>ITEM0497</td>\n",
       "      <td>46.07</td>\n",
       "      <td>78.31</td>\n",
       "      <td>48.13</td>\n",
       "      <td>5.50</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>ITEM0498</td>\n",
       "      <td>24.89</td>\n",
       "      <td>19.40</td>\n",
       "      <td>77.16</td>\n",
       "      <td>0.74</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>ITEM0499</td>\n",
       "      <td>5.12</td>\n",
       "      <td>90.64</td>\n",
       "      <td>37.67</td>\n",
       "      <td>6.44</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>ITEM0500</td>\n",
       "      <td>99.37</td>\n",
       "      <td>99.97</td>\n",
       "      <td>59.60</td>\n",
       "      <td>18.00</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id  item_height  item_width  item_length  item_weight  \\\n",
       "0    ITEM0001        29.53       82.49        89.19         4.01   \n",
       "1    ITEM0002        69.36        2.95        19.64        18.04   \n",
       "2    ITEM0003        86.38       59.71        34.78         6.12   \n",
       "3    ITEM0004        83.84       78.03        89.58        15.34   \n",
       "4    ITEM0005        16.68       44.55        64.05        17.96   \n",
       "..        ...          ...         ...          ...          ...   \n",
       "495  ITEM0496        50.30       63.68        84.41         8.84   \n",
       "496  ITEM0497        46.07       78.31        48.13         5.50   \n",
       "497  ITEM0498        24.89       19.40        77.16         0.74   \n",
       "498  ITEM0499         5.12       90.64        37.67         6.44   \n",
       "499  ITEM0500        99.37       99.97        59.60        18.00   \n",
       "\n",
       "    article_category  \n",
       "0        Electronics  \n",
       "1               Toys  \n",
       "2               Home  \n",
       "3           Clothing  \n",
       "4        Electronics  \n",
       "..               ...  \n",
       "495           Sports  \n",
       "496             Home  \n",
       "497      Electronics  \n",
       "498             Home  \n",
       "499             Home  \n",
       "\n",
       "[500 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_static = pd.read_csv('../data/article_metadata.csv')\n",
    "df_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id                       object\n",
       "timestamp             datetime64[ns]\n",
       "target                       float64\n",
       "net_revenue_sum              float64\n",
       "listing_price_mean           float64\n",
       "net_unit_price               float64\n",
       "promo_flag                     int64\n",
       "holiday_flag                   int64\n",
       "weekend_flag                   int64\n",
       "holiday_ahead                  int64\n",
       "promo_ahead                    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### some pre processing\n",
    "static_feature_cols = ['item_height','item_width','item_length','item_weight','article_category']\n",
    "for col in static_feature_cols:\n",
    "    if col in df_ts.columns:\n",
    "        df_ts = df_ts.drop(col, axis=1)\n",
    "\n",
    "df_ts['timestamp'] = pd.to_datetime(df_ts['timestamp'])\n",
    "bool_cols = df_ts.select_dtypes(include=['bool']).columns\n",
    "for col in bool_cols:\n",
    "    df_ts[col] = df_ts[col].astype(int)\n",
    "df_ts.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize values and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_covariates = ['listing_price_mean','net_unit_price','promo_flag','holiday_flag','weekend_flag','holiday_ahead','promo_ahead']\n",
    "prediction_length = 90\n",
    "start_date = '2020-01-01'\n",
    "test_start_date=\"2023-11-03\" \n",
    "test_end_date=\"2024-02-01\" \n",
    "TARGET = 'target'\n",
    "trial_name = 'autogluon_ensemble_trial_1'\n",
    "model_path = f'/home/sagemaker-user/Homepro_AWS_competancy/models/{trial_name}'\n",
    "TRAIN_TIME_LIMIT =12000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### perform train-test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 23:20:06.601124: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-18 23:20:06.649185: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted to timeseries df\n"
     ]
    }
   ],
   "source": [
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "ts = TimeSeriesDataFrame.from_data_frame(df_ts)\n",
    "ts.static_features = df_static.set_index(\"item_id\")\n",
    "ts = ts.sort_index()\n",
    "print(\"converted to timeseries df\")\n",
    "filtered_ts = ts.slice_by_time(start_time=pd.Timestamp(start_date), end_time=pd.Timestamp(test_end_date))\n",
    "train_data, test_data = filtered_ts.train_test_split(prediction_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### min history has to be 2*prediction_length+1 days (prediction_length days is the test period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = pd.Timestamp(test_end_date) - pd.Timedelta(days=3*prediction_length+1)\n",
    "filtered_test_data = test_data.slice_by_time(start_time=min_date, end_time=pd.Timestamp(test_end_date))\n",
    "test_item_counts = filtered_test_data.groupby(level=0).size()\n",
    "# Sort the counts in ascending order\n",
    "sorted_counts = test_item_counts.sort_values()\n",
    "test_filtered_items_to_remove = sorted_counts[sorted_counts < 3*prediction_length+1].index.tolist()\n",
    "train_data = train_data[~train_data.index.get_level_values(0).isin(test_filtered_items_to_remove)]\n",
    "test_data = test_data[~test_data.index.get_level_values(0).isin(test_filtered_items_to_remove)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1\"\n",
      "================ TimeSeriesPredictor ================\n",
      "TimeSeriesPredictor.fit() called\n",
      "Setting presets to: best_quality\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': 'MAPE',\n",
      " 'excluded_model_types': None,\n",
      " 'freq': None,\n",
      " 'hyperparameter_tune_kwargs': {'num_trials': 3,\n",
      "                                'scheduler': 'local',\n",
      "                                'searcher': 'auto'},\n",
      " 'hyperparameters': 'best_quality',\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 90,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 12345,\n",
      " 'refit_full': False,\n",
      " 'target': 'target',\n",
      " 'time_limit': 12000,\n",
      " 'verbosity': 4}\n",
      "\n",
      "Inferred data frequency: D\n",
      "Provided training data set with 113462 rows, 97 items (item = single time series). Average time series length is 1169.7. \n",
      "=====================================================\n",
      "Global seed set to 12345\n",
      "Beginning AutoGluon training with TimeSeriesLearner Time limit = 11999.97405052185\n",
      "AutoGluon will save models to /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'\n",
      "\tThis metric's sign has been flipped to adhere to being 'higher is better'. The reported score can be multiplied by -1 to get the metric value.\n",
      "\n",
      "Provided dataset contains following columns:\n",
      "\ttarget:           'target'\n",
      "\tknown covariates: ['listing_price_mean', 'net_unit_price', 'promo_flag', 'holiday_flag', 'weekend_flag', 'holiday_ahead', 'promo_ahead']\n",
      "\tpast covariates:  ['net_revenue_sum']\n",
      "Following types of static features have been inferred:\n",
      "\tcategorical:        ['article_category']\n",
      "\tcontinuous (float): ['item_height', 'item_width', 'item_length', 'item_weight']\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit \n",
      "Saving /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/trainer.pkl\n",
      "Saving /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/learner.pkl\n",
      "\n",
      "Starting training. Start time is 2024-06-18 23:35:41\n",
      "Saving /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/utils/data/train.pkl\n",
      "Models that will be trained: ['Naive', 'SeasonalNaive', 'Theta', 'AutoETS', 'RecursiveTabular', 'DeepAR', 'TemporalFusionTransformer', 'PatchTST', 'DirectTabular', 'AutoARIMA']\n",
      "Hyperparameter tuning model: Naive. Tuning model for up to 1200.00s of the 11999.97s remaining.\n",
      "\tFitting Naive with 'num_gpus': 0, 'num_cpus': 16\n",
      "\tWindow 0\n",
      "Shortening all time series to at most 2500\n",
      "\t\t-0.8009      = Validation score (MAPE)\n",
      "\t\t0.000   s    = Training runtime\n",
      "\t\t0.175   s    = Training runtime\n",
      "\t-0.8009       = Validation score (-MAPE)\n",
      "\t0.12    s     = Training runtime\n",
      "\t0.18    s     = Validation (prediction) runtime\n",
      "Saving /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/Naive/utils/oof.pkl\n",
      "Saving /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/Naive/model.pkl\n",
      "Saving /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/Naive/W0/model.pkl\n",
      "Hyperparameter tuning model: SeasonalNaive. Tuning model for up to 1200.00s of the 11999.97s remaining.\n",
      "\tFitting SeasonalNaive with 'num_gpus': 0, 'num_cpus': 16\n",
      "\tWindow 0\n",
      "Shortening all time series to at most 2500\n",
      "\t\t-2.1446      = Validation score (MAPE)\n",
      "\t\t0.000   s    = Training runtime\n",
      "\t\t0.179   s    = Training runtime\n",
      "\t-2.1446       = Validation score (-MAPE)\n",
      "\t0.11    s     = Training runtime\n",
      "\t0.18    s     = Validation (prediction) runtime\n",
      "Saving /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/SeasonalNaive/utils/oof.pkl\n",
      "Saving /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/SeasonalNaive/model.pkl\n",
      "Saving /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/SeasonalNaive/W0/model.pkl\n",
      "Hyperparameter tuning model: Theta. Tuning model for up to 1200.00s of the 11999.97s remaining.\n",
      "\tFitting Theta with 'num_gpus': 0, 'num_cpus': 16\n",
      "\tWindow 0\n",
      "Shortening all time series to at most 2500\n",
      "\t\t-1.4309      = Validation score (MAPE)\n",
      "\t\t0.000   s    = Training runtime\n",
      "\t\t20.148  s    = Training runtime\n",
      "\t-1.4309       = Validation score (-MAPE)\n",
      "\t0.11    s     = Training runtime\n",
      "\t20.15   s     = Validation (prediction) runtime\n",
      "Saving /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/Theta/utils/oof.pkl\n",
      "Saving /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/Theta/model.pkl\n",
      "Saving /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/Theta/W0/model.pkl\n",
      "Hyperparameter tuning model: AutoETS. Tuning model for up to 1200.00s of the 11999.97s remaining.\n",
      "\tFitting AutoETS with 'num_gpus': 0, 'num_cpus': 16\n",
      "\tWindow 0\n",
      "Shortening all time series to at most 2500\n",
      "\t\t-1.3365      = Validation score (MAPE)\n",
      "\t\t0.000   s    = Training runtime\n",
      "\t\t22.054  s    = Training runtime\n",
      "\t-1.3365       = Validation score (-MAPE)\n",
      "\t0.11    s     = Training runtime\n",
      "\t22.05   s     = Validation (prediction) runtime\n",
      "Saving /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/AutoETS/utils/oof.pkl\n",
      "Saving /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/AutoETS/model.pkl\n",
      "Saving /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/AutoETS/W0/model.pkl\n",
      "Hyperparameter tuning model: RecursiveTabular. Tuning model for up to 1200.00s of the 11999.97s remaining.\n",
      "\tFitting RecursiveTabular with 'num_gpus': 0, 'num_cpus': 16\n",
      "\tWindow 0\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/RecursiveTabular/W0/point_predictor\"\n",
      "Beginning AutoGluon training ... Time limit = 1199.9645347595215s\n",
      "AutoGluon will save models to \"/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/RecursiveTabular/W0/point_predictor\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Fri May 17 18:07:48 UTC 2024\n",
      "Disk Space Avail:   20.98 GB / 80.50 GB (26.1%)\n",
      "Train Data Rows:    95323\n",
      "Train Data Columns: 45\n",
      "Tuning Data Rows:    8730\n",
      "Tuning Data Columns: 45\n",
      "Label Column: y\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    55762.3 MB\n",
      "\tTrain Data (Original)  Memory Usage: 36.73 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['article_category']\n",
      "\t\t('float', [])    : 44 | ['listing_price_mean', 'net_unit_price', 'promo_flag', 'holiday_flag', 'weekend_flag', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  1 | ['article_category']\n",
      "\t\t('float', [])     : 39 | ['listing_price_mean', 'net_unit_price', 'item_height', 'item_width', 'item_length', ...]\n",
      "\t\t('int', ['bool']) :  5 | ['promo_flag', 'holiday_flag', 'weekend_flag', 'holiday_ahead', 'promo_ahead']\n",
      "\t0.4s = Fit runtime\n",
      "\t45 features in original data used to generate 45 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 33.09 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.53s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {'proc.impute_strategy': 'constant'},\n",
      "\t'GBM': [{}, {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}],\n",
      "}\n",
      "Fitting 3 L1 models ...\n",
      "Fitting model: LightGBM ... Training model for up to 1199.44s of the 1199.44s of remaining time.\n",
      "\t-2.0039\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 1198.65s of the 1198.65s of remaining time.\n",
      "\t-1.23\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 1197.91s of the 1197.91s of remaining time.\n",
      "\t-4.7784\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t38.94s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1158.93s of remaining time.\n",
      "\t-1.23\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 41.42s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/RecursiveTabular/W0/point_predictor\")\n",
      "\t\t-2.2411      = Validation score (MAPE)\n",
      "\t\t41.981  s    = Training runtime\n",
      "\t\t2.000   s    = Training runtime\n",
      "\t-2.2411       = Validation score (-MAPE)\n",
      "\t42.09   s     = Training runtime\n",
      "\t2.00    s     = Validation (prediction) runtime\n",
      "Hyperparameter tuning model: DeepAR. Tuning model for up to 1200.00s of the 11999.97s remaining.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d84e2424cef434eba321689899c5aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tHyperparameter tune run: DeepAR/T1\n",
      "\t\t-0.6924      = Validation score (MAPE)\n",
      "\t\t99.831  s    = Training runtime\n",
      "\t\t1.666   s    = Training runtime\n",
      "\tHyperparameter tune run: DeepAR/T2\n",
      "\t\t-0.6592      = Validation score (MAPE)\n",
      "\t\t96.092  s    = Training runtime\n",
      "\t\t1.901   s    = Training runtime\n",
      "\tHyperparameter tune run: DeepAR/T3\n",
      "\t\t-0.6643      = Validation score (MAPE)\n",
      "\t\t114.307 s    = Training runtime\n",
      "\t\t4.401   s    = Training runtime\n",
      "\tTrained 3 models while tuning DeepAR.\n",
      "\t-0.6592       = Validation score (-MAPE)\n",
      "\t310.33  s     = Total tuning time\n",
      "\tBest hyperparameter configuration: {'num_layers': 2, 'hidden_size': 59}\n",
      "Hyperparameter tuning model: TemporalFusionTransformer. Tuning model for up to 1200.00s of the 11999.97s remaining.\n",
      "\tWindow 0\n",
      "GluonTS logging is turned on during training. Note that losses reported by GluonTS may not correspond to those specified via `eval_metric`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/TemporalFusionTransformer/W0/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                           | Params | In sizes | Out sizes \n",
      "---------------------------------------------------------------------------------\n",
      "0 | model | TemporalFusionTransformerModel | 127 K  | ?        | [1, 9, 90]\n",
      "---------------------------------------------------------------------------------\n",
      "127 K     Trainable params\n",
      "0         Non-trainable params\n",
      "127 K     Total params\n",
      "0.509     Total estimated model params size (MB)\n",
      "Epoch 0, global step 50: 'val_loss' reached 337.61728 (best 337.61728), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/TemporalFusionTransformer/W0/lightning_logs/version_0/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'val_loss' was not in top 1\n",
      "Epoch 2, global step 150: 'val_loss' was not in top 1\n",
      "Epoch 3, global step 200: 'val_loss' reached 336.09744 (best 336.09744), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/TemporalFusionTransformer/W0/lightning_logs/version_0/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'val_loss' was not in top 1\n",
      "Epoch 5, global step 300: 'val_loss' reached 333.94141 (best 333.94141), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/TemporalFusionTransformer/W0/lightning_logs/version_0/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'val_loss' reached 328.11884 (best 328.11884), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/TemporalFusionTransformer/W0/lightning_logs/version_0/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'val_loss' was not in top 1\n",
      "Epoch 8, global step 450: 'val_loss' reached 327.50824 (best 327.50824), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/TemporalFusionTransformer/W0/lightning_logs/version_0/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'val_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'val_loss' reached 326.13446 (best 326.13446), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/TemporalFusionTransformer/W0/lightning_logs/version_0/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'val_loss' reached 324.47748 (best 324.47748), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/TemporalFusionTransformer/W0/lightning_logs/version_0/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'val_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'val_loss' reached 324.24347 (best 324.24347), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/TemporalFusionTransformer/W0/lightning_logs/version_0/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'val_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'val_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'val_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'val_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'val_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'val_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'val_loss' reached 323.74606 (best 323.74606), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/TemporalFusionTransformer/W0/lightning_logs/version_0/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'val_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'val_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'val_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'val_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'val_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'val_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'val_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'val_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'val_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'val_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'val_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'val_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'val_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'val_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'val_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'val_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'val_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'val_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'val_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'val_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'val_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'val_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'val_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'val_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'val_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'val_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'val_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'val_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'val_loss' was not in top 1\n",
      "Epoch 50, global step 2550: 'val_loss' was not in top 1\n",
      "Epoch 51, global step 2600: 'val_loss' was not in top 1\n",
      "Epoch 52, global step 2650: 'val_loss' was not in top 1\n",
      "Epoch 53, global step 2700: 'val_loss' was not in top 1\n",
      "Epoch 54, global step 2750: 'val_loss' was not in top 1\n",
      "Epoch 55, global step 2800: 'val_loss' was not in top 1\n",
      "Epoch 56, global step 2850: 'val_loss' was not in top 1\n",
      "Epoch 57, global step 2900: 'val_loss' was not in top 1\n",
      "Epoch 58, global step 2950: 'val_loss' was not in top 1\n",
      "Epoch 59, global step 3000: 'val_loss' was not in top 1\n",
      "Epoch 60, global step 3050: 'val_loss' was not in top 1\n",
      "Epoch 61, global step 3100: 'val_loss' was not in top 1\n",
      "Epoch 62, global step 3150: 'val_loss' was not in top 1\n",
      "Epoch 63, global step 3200: 'val_loss' was not in top 1\n",
      "Epoch 64, global step 3250: 'val_loss' was not in top 1\n",
      "Epoch 65, global step 3300: 'val_loss' was not in top 1\n",
      "Epoch 66, global step 3350: 'val_loss' was not in top 1\n",
      "Epoch 67, global step 3400: 'val_loss' was not in top 1\n",
      "Epoch 68, global step 3450: 'val_loss' was not in top 1\n",
      "Epoch 69, global step 3500: 'val_loss' was not in top 1\n",
      "Epoch 70, global step 3550: 'val_loss' was not in top 1\n",
      "Epoch 71, global step 3600: 'val_loss' was not in top 1\n",
      "Epoch 72, global step 3650: 'val_loss' was not in top 1\n",
      "Epoch 73, global step 3700: 'val_loss' was not in top 1\n",
      "Epoch 74, global step 3750: 'val_loss' was not in top 1\n",
      "Epoch 75, global step 3800: 'val_loss' was not in top 1\n",
      "Epoch 76, global step 3850: 'val_loss' was not in top 1\n",
      "Epoch 77, global step 3900: 'val_loss' was not in top 1\n",
      "Epoch 78, global step 3950: 'val_loss' was not in top 1\n",
      "Epoch 79, global step 4000: 'val_loss' was not in top 1\n",
      "Epoch 80, global step 4050: 'val_loss' was not in top 1\n",
      "Epoch 81, global step 4100: 'val_loss' was not in top 1\n",
      "Epoch 82, global step 4150: 'val_loss' was not in top 1\n",
      "Epoch 83, global step 4200: 'val_loss' was not in top 1\n",
      "Epoch 84, global step 4250: 'val_loss' was not in top 1\n",
      "Epoch 85, global step 4300: 'val_loss' was not in top 1\n",
      "Epoch 86, global step 4350: 'val_loss' was not in top 1\n",
      "Epoch 87, global step 4400: 'val_loss' was not in top 1\n",
      "Epoch 88, global step 4450: 'val_loss' was not in top 1\n",
      "Epoch 89, global step 4500: 'val_loss' was not in top 1\n",
      "Epoch 90, global step 4550: 'val_loss' was not in top 1\n",
      "Epoch 91, global step 4600: 'val_loss' was not in top 1\n",
      "Epoch 92, global step 4650: 'val_loss' was not in top 1\n",
      "Epoch 93, global step 4700: 'val_loss' was not in top 1\n",
      "Epoch 94, global step 4750: 'val_loss' was not in top 1\n",
      "Epoch 95, global step 4800: 'val_loss' was not in top 1\n",
      "Epoch 96, global step 4850: 'val_loss' was not in top 1\n",
      "Epoch 97, global step 4900: 'val_loss' was not in top 1\n",
      "Epoch 98, global step 4950: 'val_loss' was not in top 1\n",
      "Epoch 99, global step 5000: 'val_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "INFO:gluonts.torch.model.estimator:Loading best model from /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/TemporalFusionTransformer/W0/lightning_logs/version_0/checkpoints/epoch=20-step=1050.ckpt\n",
      "Removing lightning_logs directory /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/TemporalFusionTransformer/W0/lightning_logs\n",
      "Predicting with time series model TemporalFusionTransformer/W0\n",
      "\tProvided data for prediction with 104732 rows, 97 items. Average time series length is 1079.7113402061855.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "WARNING:gluonts.model.forecast:The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n",
      "\t\t-0.6881      = Validation score (MAPE)\n",
      "\t\t180.193 s    = Training runtime\n",
      "\t\t0.342   s    = Training runtime\n",
      "\t-0.6881       = Validation score (-MAPE)\n",
      "\t180.31  s     = Training runtime\n",
      "\t0.34    s     = Validation (prediction) runtime\n",
      "Hyperparameter tuning model: PatchTST. Tuning model for up to 1200.00s of the 11999.97s remaining.\n",
      "\tWindow 0\n",
      "GluonTS logging is turned on during training. Note that losses reported by GluonTS may not correspond to those specified via `eval_metric`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/PatchTST/W0/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type          | Params\n",
      "----------------------------------------\n",
      "0 | model | PatchTSTModel | 1.1 M \n",
      "----------------------------------------\n",
      "1.1 M     Trainable params\n",
      "384       Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.541     Total estimated model params size (MB)\n",
      "Epoch 0, global step 50: 'val_loss' reached 4.65410 (best 4.65410), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/PatchTST/W0/lightning_logs/version_0/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'val_loss' was not in top 1\n",
      "Epoch 2, global step 150: 'val_loss' reached 4.63098 (best 4.63098), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/PatchTST/W0/lightning_logs/version_0/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'val_loss' was not in top 1\n",
      "Epoch 4, global step 250: 'val_loss' reached 4.61668 (best 4.61668), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/PatchTST/W0/lightning_logs/version_0/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'val_loss' reached 4.59142 (best 4.59142), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/PatchTST/W0/lightning_logs/version_0/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'val_loss' was not in top 1\n",
      "Epoch 7, global step 400: 'val_loss' was not in top 1\n",
      "Epoch 8, global step 450: 'val_loss' was not in top 1\n",
      "Epoch 9, global step 500: 'val_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'val_loss' reached 4.57683 (best 4.57683), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/PatchTST/W0/lightning_logs/version_0/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'val_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'val_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'val_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'val_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'val_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'val_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'val_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'val_loss' reached 4.57198 (best 4.57198), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/PatchTST/W0/lightning_logs/version_0/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'val_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'val_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'val_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'val_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'val_loss' reached 4.56404 (best 4.56404), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/PatchTST/W0/lightning_logs/version_0/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'val_loss' reached 4.56227 (best 4.56227), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/PatchTST/W0/lightning_logs/version_0/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'val_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'val_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'val_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'val_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'val_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'val_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'val_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'val_loss' reached 4.55873 (best 4.55873), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/PatchTST/W0/lightning_logs/version_0/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'val_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'val_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'val_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'val_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'val_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'val_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'val_loss' reached 4.55522 (best 4.55522), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/PatchTST/W0/lightning_logs/version_0/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'val_loss' reached 4.55432 (best 4.55432), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/PatchTST/W0/lightning_logs/version_0/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'val_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'val_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'val_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'val_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'val_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'val_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'val_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'val_loss' reached 4.54949 (best 4.54949), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/PatchTST/W0/lightning_logs/version_0/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'val_loss' was not in top 1\n",
      "Epoch 50, global step 2550: 'val_loss' was not in top 1\n",
      "Epoch 51, global step 2600: 'val_loss' was not in top 1\n",
      "Epoch 52, global step 2650: 'val_loss' was not in top 1\n",
      "Epoch 53, global step 2700: 'val_loss' was not in top 1\n",
      "Epoch 54, global step 2750: 'val_loss' was not in top 1\n",
      "Epoch 55, global step 2800: 'val_loss' was not in top 1\n",
      "Epoch 56, global step 2850: 'val_loss' was not in top 1\n",
      "Epoch 57, global step 2900: 'val_loss' was not in top 1\n",
      "Epoch 58, global step 2950: 'val_loss' was not in top 1\n",
      "Epoch 59, global step 3000: 'val_loss' was not in top 1\n",
      "Epoch 60, global step 3050: 'val_loss' was not in top 1\n",
      "Epoch 61, global step 3100: 'val_loss' was not in top 1\n",
      "Epoch 62, global step 3150: 'val_loss' was not in top 1\n",
      "Epoch 63, global step 3200: 'val_loss' was not in top 1\n",
      "Epoch 64, global step 3250: 'val_loss' was not in top 1\n",
      "Epoch 65, global step 3300: 'val_loss' was not in top 1\n",
      "Epoch 66, global step 3350: 'val_loss' was not in top 1\n",
      "Epoch 67, global step 3400: 'val_loss' was not in top 1\n",
      "Epoch 68, global step 3450: 'val_loss' was not in top 1\n",
      "Epoch 69, global step 3500: 'val_loss' was not in top 1\n",
      "Epoch 70, global step 3550: 'val_loss' was not in top 1\n",
      "Epoch 71, global step 3600: 'val_loss' reached 4.54870 (best 4.54870), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/PatchTST/W0/lightning_logs/version_0/checkpoints/epoch=71-step=3600.ckpt' as top 1\n",
      "Epoch 72, global step 3650: 'val_loss' was not in top 1\n",
      "Epoch 73, global step 3700: 'val_loss' was not in top 1\n",
      "Epoch 74, global step 3750: 'val_loss' reached 4.54460 (best 4.54460), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/PatchTST/W0/lightning_logs/version_0/checkpoints/epoch=74-step=3750.ckpt' as top 1\n",
      "Epoch 75, global step 3800: 'val_loss' reached 4.54374 (best 4.54374), saving model to '/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/PatchTST/W0/lightning_logs/version_0/checkpoints/epoch=75-step=3800.ckpt' as top 1\n",
      "Epoch 76, global step 3850: 'val_loss' was not in top 1\n",
      "Epoch 77, global step 3900: 'val_loss' was not in top 1\n",
      "Epoch 78, global step 3950: 'val_loss' was not in top 1\n",
      "Epoch 79, global step 4000: 'val_loss' was not in top 1\n",
      "Epoch 80, global step 4050: 'val_loss' was not in top 1\n",
      "Epoch 81, global step 4100: 'val_loss' was not in top 1\n",
      "Epoch 82, global step 4150: 'val_loss' was not in top 1\n",
      "Epoch 83, global step 4200: 'val_loss' was not in top 1\n",
      "Epoch 84, global step 4250: 'val_loss' was not in top 1\n",
      "Epoch 85, global step 4300: 'val_loss' was not in top 1\n",
      "Epoch 86, global step 4350: 'val_loss' was not in top 1\n",
      "Epoch 87, global step 4400: 'val_loss' was not in top 1\n",
      "Epoch 88, global step 4450: 'val_loss' was not in top 1\n",
      "Epoch 89, global step 4500: 'val_loss' was not in top 1\n",
      "Epoch 90, global step 4550: 'val_loss' was not in top 1\n",
      "Epoch 91, global step 4600: 'val_loss' was not in top 1\n",
      "Epoch 92, global step 4650: 'val_loss' was not in top 1\n",
      "Epoch 93, global step 4700: 'val_loss' was not in top 1\n",
      "Epoch 94, global step 4750: 'val_loss' was not in top 1\n",
      "Epoch 95, global step 4800: 'val_loss' was not in top 1\n",
      "Epoch 96, global step 4850: 'val_loss' was not in top 1\n",
      "Epoch 97, global step 4900: 'val_loss' was not in top 1\n",
      "Epoch 98, global step 4950: 'val_loss' was not in top 1\n",
      "Epoch 99, global step 5000: 'val_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "INFO:gluonts.torch.model.estimator:Loading best model from /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/PatchTST/W0/lightning_logs/version_0/checkpoints/epoch=75-step=3800.ckpt\n",
      "Removing lightning_logs directory /home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/PatchTST/W0/lightning_logs\n",
      "Predicting with time series model PatchTST/W0\n",
      "\tProvided data for prediction with 104732 rows, 97 items. Average time series length is 1079.7113402061855.\n",
      "\t\t-0.7635      = Validation score (MAPE)\n",
      "\t\t55.466  s    = Training runtime\n",
      "\t\t0.498   s    = Training runtime\n",
      "\t-0.7635       = Validation score (-MAPE)\n",
      "\t55.58   s     = Training runtime\n",
      "\t0.50    s     = Validation (prediction) runtime\n",
      "Hyperparameter tuning model: DirectTabular. Tuning model for up to 1200.00s of the 11999.97s remaining.\n",
      "\tWindow 0\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/DirectTabular/W0\"\n",
      "Beginning AutoGluon training ... Time limit = 1194.01522397995s\n",
      "AutoGluon will save models to \"/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/DirectTabular/W0\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Fri May 17 18:07:48 UTC 2024\n",
      "Disk Space Avail:   20.98 GB / 80.50 GB (26.1%)\n",
      "Train Data Rows:    96002\n",
      "Train Data Columns: 285\n",
      "Tuning Data Rows:    8730\n",
      "Tuning Data Columns: 285\n",
      "Label Column: target\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    61139.7 MB\n",
      "\tTrain Data (Original)  Memory Usage: 238.06 MB (0.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 10): ['holiday_ahead_lag_4', 'holiday_ahead_lag_21', 'holiday_ahead_lag_364', 'holiday_ahead_lag_365', 'holiday_ahead_lag_728', 'promo_ahead_lag_4', 'promo_ahead_lag_21', 'promo_ahead_lag_364', 'promo_ahead_lag_365', 'promo_ahead_lag_728']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 10 | ['holiday_ahead_lag_4', 'holiday_ahead_lag_21', 'holiday_ahead_lag_364', 'holiday_ahead_lag_365', 'holiday_ahead_lag_728', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['article_category']\n",
      "\t\t('float', [])    : 274 | ['target_lag_1', 'target_lag_2', 'target_lag_3', 'target_lag_4', 'target_lag_5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :   1 | ['article_category']\n",
      "\t\t('float', [])     : 269 | ['target_lag_1', 'target_lag_2', 'target_lag_3', 'target_lag_4', 'target_lag_5', ...]\n",
      "\t\t('int', ['bool']) :   5 | ['promo_flag_lag_0', 'holiday_flag_lag_0', 'weekend_flag_lag_0', 'holiday_ahead_lag_0', 'promo_ahead_lag_0']\n",
      "\t6.3s = Fit runtime\n",
      "\t275 features in original data used to generate 275 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 226.01 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 6.69s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'GBM': {},\n",
      "}\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM ... Training model for up to 1187.32s of the 1187.32s of remaining time.\n",
      "\t-32074773717790.84\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t2.39s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1184.9s of remaining time.\n",
      "\t-32074773717790.84\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 10.47s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/sagemaker-user/Homepro_AWS_competancy/models/autogluon_ensemble_trial_1/models/DirectTabular/W0\")\n",
      "\t\t-0.8769      = Validation score (MAPE)\n",
      "\t\t17.234  s    = Training runtime\n",
      "\t\t2.514   s    = Training runtime\n",
      "\t-0.8769       = Validation score (-MAPE)\n",
      "\t17.35   s     = Training runtime\n",
      "\t2.51    s     = Validation (prediction) runtime\n",
      "Hyperparameter tuning model: AutoARIMA. Tuning model for up to 1200.00s of the 11999.97s remaining.\n",
      "\tWindow 0\n",
      "\t\t-1.0458      = Validation score (MAPE)\n",
      "\t\t0.000   s    = Training runtime\n",
      "\t\t32.058  s    = Training runtime\n",
      "\t-1.0458       = Validation score (-MAPE)\n",
      "\t0.11    s     = Training runtime\n",
      "\t32.06   s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\t-0.6535       = Validation score (-MAPE)\n",
      "\t7.49    s     = Training runtime\n",
      "\t6.48    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['Naive', 'SeasonalNaive', 'Theta', 'AutoETS', 'RecursiveTabular', 'DeepAR/T1', 'DeepAR/T2', 'DeepAR/T3', 'TemporalFusionTransformer', 'PatchTST', 'DirectTabular', 'AutoARIMA', 'WeightedEnsemble']\n",
      "Total runtime: 693.98 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.6535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.timeseries.predictor.TimeSeriesPredictor at 0x7f9a7c2eff10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = TimeSeriesPredictor(\n",
    "        prediction_length = prediction_length,\n",
    "        path=f'{model_path}',\n",
    "        target=TARGET,\n",
    "        eval_metric='MAPE',#'MASE',#'RMSE',\n",
    "        known_covariates_names=known_covariates,\n",
    "        verbosity=4,\n",
    ")\n",
    "# ## Training AutoGluon Model\n",
    "predictor.fit(\n",
    "        train_data,\n",
    "        presets='best_quality',\n",
    "        time_limit=TRAIN_TIME_LIMIT,\n",
    "        random_seed=12345,\n",
    "        # hyperparameters={\n",
    "        #     \"DeepAR\":{#}\n",
    "        #         \"batch_size\":64,\n",
    "        #         \"num_batches_per_epoch\": 22,\n",
    "        #         \"hidden_dim\": 128,\n",
    "        #         \"max_epochs\": 100, \n",
    "        #         \"context_length\": 120,\n",
    "        #         \"num_layers\": 3,\n",
    "        #     },\n",
    "        # },\n",
    "        # # hyperparameter_tune_kwargs=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we can see that DeepAR is performing the best with the HP configuration suggested\n",
    "\tHyperparameter tune run: DeepAR/T1\n",
    "\t\t-0.6924      = Validation score (MAPE)\n",
    "\t\t99.831  s    = Training runtime\n",
    "\t\t1.666   s    = Training runtime\n",
    "\tHyperparameter tune run: DeepAR/T2\n",
    "\t\t-0.6592      = Validation score (MAPE)\n",
    "\t\t96.092  s    = Training runtime\n",
    "\t\t1.901   s    = Training runtime\n",
    "\tHyperparameter tune run: DeepAR/T3\n",
    "\t\t-0.6643      = Validation score (MAPE)\n",
    "\t\t114.307 s    = Training runtime\n",
    "\t\t4.401   s    = Training runtime\n",
    "\tTrained 3 models while tuning DeepAR.\n",
    "\t-0.6592       = Validation score (-MAPE)\n",
    "\t310.33  s     = Total tuning time\n",
    "\tBest hyperparameter configuration: {'num_layers': 2, 'hidden_size': 59}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
